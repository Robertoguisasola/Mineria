{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minería de datos\n",
    "\n",
    "<h2 style=\"display: inline-block; padding: 4mm; padding-left: 2em; background-color: navy; line-height: 1.3em; color: white; border-radius: 10px;\">Práctica Final Minería de Datos</h2>\n",
    "\n",
    "## Docentes\n",
    "\n",
    " - José Francisco Diez Pastor\n",
    " \n",
    "## Estudiantes\n",
    "\n",
    "- Rodrigo Pascual García\n",
    "- Roberto Martínez - Guisasola Guerrero"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción de la práctica\n",
    "\n",
    "Tenemos un conjunto de datos de pacientes que han acudido a una consulta de un Servicio de Cardiología. En total son más de 69.000 pacientes y para cada uno de ellos tenemos 12 atributos. Estos datos han sido extraidos de <a href = \"https://www.kaggle.com/datasets/bhadaneeraj/cardio-vascular-disease-detection?select=cardio_train.csv\">Kaggle</a>.<br>\n",
    "Se desea predecir si el paciente tiene una enfermedad cardíaca o no.\n",
    "\n",
    "### Descripción de los atributos\n",
    "Los atributos del conjuto de datos son:\n",
    "- Edad: valor objetivo que indica los días de vida del paciente. Es un valor numérico\n",
    "- Altura: altura del paciente medida en centímetros. Es un valor numérico\n",
    "- Peso: peso del paciente medido en kilogramos. Es un valor numérico\n",
    "- Sexo: sexo del paciente. Es un atributo binario. 1: Hombre, 2: Mujer\n",
    "- PSis: presión sistólica del paciente medida en la consulta durante la exploración médica. Es un valor numérico expresado en mmHg\n",
    "- PDia: presión diastólica del paciente medida en la consulta durante la exploración médica. Es un valor numérico expresado en mmHg\n",
    "- Colesterol: indica el estado de los niveles de colesterol obtenidos en un análisis sanguíneo. Es un atributo categórico. 1:Normal, 2: Alto, 3: Muy alto\n",
    "- Glucosa: indica el estado de los niveles de glucosa obtenidos mediante una prueba de glucosa en sangre. Es un atributo categórico. 1:Normal, 2: Alto, 3: Muy alto\n",
    "- Fumador: atributo que indica si el paciente fuma o no. Es un atributo binario. 0: No, 1: Sí\n",
    "- Alcohol: atributo que indica si el paciente consume alcohol de manera abundante. Es un atributo binario. 0: No, 1: Sí\n",
    "- Act_fisica: atributo que indica si el paciente realiza actividad física de manera regular. Es un atributo binario. 0: No, 1: Sí\n",
    "\n",
    "#### La clase\n",
    "- Cardio: presencia o ausencia de enfermedad cardiovascular. Es la variable que se quiere predecir. Es un atributo binario. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"index\"></a>\n",
    "## Tareas realizadas\n",
    "\n",
    "1. [Carga y visualización de los datos](#1)\n",
    "2. [Combinar los DataFrames en uno solo **(1 Puntos)**](#2)\n",
    "3. [Calculo de atributos derivados **(1.5 Puntos)**](#3)\n",
    "4. [Crea una función que devuelve estadísticas básicas **(2 Puntos)**](#4)\n",
    "5. [Elimina los valores desconocidos **(1 Puntos)**](#5)\n",
    "6. [Gráficas básicas **(1.5 Puntos)**](#6)\n",
    "7. [Gráficas básicas 2 **(2.5 Puntos)**](#7)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga y visualización de los datos <a id=\"1\"></a><a href=\"#index\"><i class=\"fa fa-list-alt\" aria-hidden=\"true\"></i></a>\n",
    "Es la primera etapa. Vamos a cargar el conjunto de datos disponible en el fichero local `cardio_train.csv` y, puesto que se encuentra en inglés, vamos a poner el nombre de las columnas en castellano. Para ello hemos empleado la función `load_data` <br>\n",
    "También hemos creado nuestra propia función `mostrar_cabecera`, que muestra la cabecera del conjunto de datos y tantas filas como se le indique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def load_data(url):\n",
    "    \"\"\"\n",
    "    Función que recibe una url (direccion del equipo con los datos en formato csv) y devuelve un Dataframe con los datos. Las cabeceras de las columnas\n",
    "    son eliminadas y se ponen en castellano automáticamente al ser importadas\n",
    "\n",
    "    Parámetros:\n",
    "    ----------    \n",
    "        url : string\n",
    "            Dirección del fichero a cargar. No tiene ningún valor por defecto.\n",
    "\n",
    "    Return:\n",
    "    ----------    \n",
    "        DataFrame (df): devuelve un DataFrame con los datos del fichero proporcionado.\n",
    "    \"\"\"\n",
    "    dataframe = pd.read_csv(url, sep = ';')\n",
    "    columnas = list(dataframe.columns.values)\n",
    "    print(f\"El conjunto de datos se ha importado. Las columnas originales ({columnas}) se encuentran en inglés. Las columnas van a ser traducidas al castellano\")\n",
    "    columnasNuevas = ['Id', 'Edad', 'Sexo', 'Altura', 'Peso', 'PSis', 'PDia', 'Colesterol', 'Glucosa', 'Fumador', 'Alcohol', 'Act_fisica', 'Cardio']\n",
    "    dataframe.columns = columnasNuevas\n",
    "    print(f\"Columnas traducidas al castellano. Columnas actuales: {columnasNuevas}\")\n",
    "    procesado = False  \n",
    "    return dataframe, procesado\n",
    "\n",
    "def mostrar_cabecera(df, n):\n",
    "    \"\"\"\n",
    "    Recibe un DataFrame de los datos y devuelve un DataFrame formado por las n primeras columnas.\n",
    "\n",
    "    Parámetros:\n",
    "    ----------    \n",
    "        df : DataFrame\n",
    "            DataFrame del cual se quieren mostrar las 10 primeras filas. No tiene ningún valor por defecto.\n",
    "        \n",
    "        n : int\n",
    "            Número de filas del Da\n",
    "            taFrame que se quieren mostrar.\n",
    "\n",
    "    Return:\n",
    "    ----------    \n",
    "        Muestra las n primeras filas del DataFrame proporcionado.\n",
    "    \"\"\"\n",
    "    print(f\"A continuación, se muestran las {n} primeras filas del conjunto de datos\")\n",
    "    display(df.head(n=n))\n",
    "\n",
    "url = \".\"+os.sep+\"data\"+os.sep+\"cardio_train.csv\"\n",
    "df, procesado = load_data(url)\n",
    "mostrar_cabecera(df, 10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limieza de datos\n",
    "Para poder obtener la mejor solución y que el programa sea capaz de diagnosticar con la mayor precisión, es necesario que dispongamos de datos precisos. Hay ciertos valores que pueden ser erróneos o que estén mal introducidos debido a un error humano <br>\n",
    "Para realizar esta limpieza de los datos hemos usado la función `limpieza_datos`, que realiza las siguientes acciones:\n",
    "\n",
    "- Id: borramos la columna\n",
    "- Edad: pasaremos de dias a años\t\n",
    "- Altura: borraremos esta columna, ya que se reflejará en el IMC\n",
    "- Peso:\tborraremos esta columna, ya que se reflejará en el IMC\n",
    "- PSis: haremos nulos los valores que no sean posibles\t\n",
    "- PDia: haremos nulos los valores que no sean posibles\n",
    "\n",
    "Para evitar errores en el programa, si el DataFrame ya había sido procesado, de manera que hay columnas que ya no existen, la función no realiza las anteriores acciones y muestra la frase `El DataFrame ya ha sido procesado`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpieza_datos(df, procesado):\n",
    "    '''\n",
    "    Función que recibe un DataFrame y devuelve un Dataframe con el IMC calculado y las columnas referentes al peso y a la altura eliminadas.\n",
    "\n",
    "    Parámetros:\n",
    "    ----------    \n",
    "        df : DataFrame\n",
    "            DataFrame del cual se quieren procesar los datos y calcular el IMC de los pacientes. No tiene ningún valor por defecto.\n",
    "\n",
    "    Return:\n",
    "    ----------    \n",
    "        DataFrame (df): devuelve un DataFrame con los datos calculados y las columnas referentes al peso y a la altura eliminadas\n",
    "    '''\n",
    "    if not procesado:\n",
    "        #Edad: pasaremos de dias a años\n",
    "        df['EDAD'] = (df.Edad/365)\n",
    "        df.drop(['Edad'], axis=1, inplace = True)\n",
    "        \n",
    "        #Altura y peso: usaremos este dato para calcular el Indice de masa corporal y lo borraremos\n",
    "        df['BMI'] = (df.Peso/((df.Altura/100)**2))\n",
    "        df.drop(['Altura', 'Peso'], axis=1, inplace = True)\n",
    "        \n",
    "        #Id: Borrado\n",
    "        df.drop(['Id'], axis=1, inplace = True)\n",
    "        \n",
    "        #Correción valores de presón\n",
    "        df.loc[~df['PSis'].between(55, 300), 'PSis'] = np.nan\n",
    "        df.loc[~df['PDia'].between(30, 150), 'PDia'] = np.nan\n",
    "        \n",
    "        #correción valores de BMI\n",
    "        df.loc[~df['BMI'].between(10, 50), 'BMI'] = np.nan\n",
    "        \n",
    "        df = df[['EDAD', 'Sexo', 'BMI', 'PSis', 'PDia', 'Colesterol', 'Glucosa', 'Fumador', 'Alcohol', 'Act_fisica','Cardio']]\n",
    "        columnasNuevas = ['Edad', 'Sexo', 'IMC', 'PSis','PDia','Colesterol','Glucosa','Fumador','Alcohol', 'Act_fisica','Cardio']\n",
    "        df.columns = columnasNuevas\n",
    "\n",
    "        procesado = True\n",
    "    else:\n",
    "        print(\"El DataFrame ya ha sido procesado\")\n",
    "    \n",
    "    return round(df,2), procesado\n",
    "\n",
    "df, procesado = limpieza_datos(df, procesado)\n",
    "mostrar_cabecera(df, 7)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Información sobre las columnas y calcular estadísticas\n",
    "Es importante conocer la información que hay en cada columna, así como sus estadísticas. Para ello, hemos creado una función llamada `informacionColumnas`, que proporciona información acerca del número de filas y columnas del DataFrame. Esta función también muestra el número de ejemplos que hay en cada uno de los posibles valores de un listado de columnas proporcionado, gracias a la función `datosColumna`. Por defecto, muestra la información de la columna `Cardio`<br>\n",
    "\n",
    "Una vez conocidos los valores de las columnas deseadas, mostramos las estadisticas de cada columna del DataFrame con la función `mostrarEstadisticas`. Esta función recibe el DataFrame y un listado de estadísticas que se quieren mostrar. También indica el número de valores nulos que hay en una columna. Todos estos valores son redondeados con dos decimales "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def informacionColumnas(df, lColumnas = [\"Cardio\"]):\n",
    "    \"\"\"\n",
    "    Recibe el DataFrame de los datos y un listado de columnas y muestra el número de filas y columnas y cuantos ejemplos hay en cada una de las clases de cada columna.\n",
    "    \n",
    "    Parámetros:\n",
    "    ----------    \n",
    "        df : DataFrame\n",
    "            DataFrame del cual se quiere conocer la información. No tiene ningún valor por defecto.\n",
    "\n",
    "        class_name : list\n",
    "            Listado de columnas de las cuales se quiere obtener sus estadísticas\n",
    "\n",
    "    Return:\n",
    "    ----------    \n",
    "        Muestra el número de filas y columnas del DataFrame proporcionado.\\n\n",
    "        Además, indica el número de ejemplos que pertenecen a cada valor de cada columna, en diferentes líneas.\n",
    "    \"\"\"\n",
    "        \n",
    "    filas = len(df.index)\n",
    "    columnas = len(df.columns)\n",
    "    datos = f\"El dataset está formado por {filas} filas y {columnas} columnas. \\nA continuación, se muestran unas estadísticas de cada columna empleada:\\n\"\n",
    "    for i in lColumnas:\n",
    "        datos = datos + datosColumna(df, i)\n",
    "    print(datos)\n",
    "    \n",
    "\n",
    "def datosColumna(df,columna):\n",
    "    \"\"\"\n",
    "    Recibe el DataFrame de los datos y el nombre de una columna y devuelve un string con el número de ejemplos que hay en cada uno de los posibles \n",
    "    valores de la columna y algunos valores estadísticos\n",
    "    \n",
    "    Parámetros:\n",
    "    ----------    \n",
    "        df : DataFrame\n",
    "            DataFrame del cual se quiere conocer la información. No tiene ningún valor por defecto.\n",
    "\n",
    "        columna : string\n",
    "            Nombre de la columna de la cual se quiere conocer cuántos ejemplos pertenecen a cada clase. No tiene ningún valor por defecto.\n",
    "\n",
    "    Return:\n",
    "    ----------    \n",
    "        String (estadisticas): string con las estadisticas de cada columna.\\n\n",
    "    \"\"\"\n",
    "    estadisticas = f\"En la columna {columna} hay \"\n",
    "    media = 0 \n",
    "    ejemplos = df.groupby(columna).size()\n",
    "    for i in ejemplos.index:\n",
    "        estadisticas = estadisticas  + str(ejemplos[i]) + \" ejemplos de la clase \" + str(i) + \", \"\n",
    "        media = media + (i*ejemplos[i])/len(df.index)\n",
    "    estadisticas = estadisticas + \"tiene un valor medio de \" + str(media) + \"\\n\"\n",
    "    return estadisticas \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostrarEstadisticas(df, valores):\n",
    "    \"\"\"\n",
    "    Muestra estadísticas básicas de un DataFrame y el número de missings\n",
    "    \n",
    "    Parámetros:\n",
    "    ----------    \n",
    "        df : DataFrame\n",
    "            DataFrame del cual se quiere conocer la información. No tiene ningún valor por defecto.\n",
    "    \n",
    "    Return:\n",
    "    ----------    \n",
    "        DataFrame con las estadísticas del dataFrame proporcionado.\n",
    "    \"\"\"\n",
    "    estadisticas = df.describe()\n",
    "    estadisticas = estadisticas.transpose()\n",
    "    df_stats = estadisticas[valores]\n",
    "    nulos = (df.isna()).sum()\n",
    "    df_stats['Nº nulos']=nulos\n",
    "    return round(df_stats,2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas = [\"Cardio\", \"Glucosa\"]\n",
    "informacionColumnas(df, columnas)\n",
    "valoresEstadisticas = ['count', 'mean', 'std', 'min', 'max']\n",
    "mostrarEstadisticas(df, valoresEstadisticas)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamiento de valores missing <a id=\"4\"></a><a href=\"#index\"><i class=\"fa fa-list-alt\" aria-hidden=\"true\"></i></a>\n",
    "Los valores desconocidos son un problema a la hora de emplear algoritmos de clasificación, por ello vamos a sustituirlos por la media. De esta forma, el valor medio de cada columna no se verá afectado y se evitará que la toma de decisiones por parte del algoritmo sí que se modifique. Para reemplazar los valores missing hemos empleado la función `eliminarMissings`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminarMissings(df):\n",
    "    '''\n",
    "    Función que recibe un DataFrame y devuelve un Dataframe con los valores missing sustituidos por la media\n",
    "\n",
    "    Parámetros:\n",
    "    ----------    \n",
    "        df : DataFrame\n",
    "            DataFrame del cual se quieren corregir los valores missing. No tiene ningún valor por defecto.\n",
    "\n",
    "    Return:\n",
    "    ----------    \n",
    "        DataFrame (df): devuelve un DataFrame con los valores missing corregidos\n",
    "\n",
    "    '''\n",
    "    if (df.isna()).sum().sum() != 0:\n",
    "        #Recorremos los nombres de las columnas del dataframe\n",
    "        for i in df.columns:\n",
    "        #Para cada columna rellenamos los valores Na con la media de la columna\n",
    "            df[i].fillna(df[i].mean(skipna = True), inplace=True)\n",
    "    return df\n",
    "\n",
    "display(mostrarEstadisticas(df, valoresEstadisticas))\n",
    "df = eliminarMissings(df)\n",
    "mostrar_cabecera(df, 18)\n",
    "display(mostrarEstadisticas(df, valoresEstadisticas))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualización de estadísticas <a id=\"4\"></a><a href=\"#index\"><i class=\"fa fa-list-alt\" aria-hidden=\"true\"></i></a>\n",
    "En el siguiente bloque hemos decidido mostrar ciertos gráficos sobre los valores. En primer lugar, hay un gráfico de dispersión que permite al usuario escoger la columna sobre la que desea realizar el gráfico. Este gráfico es almacenado en memoria para permitir al usuario emplearlo en otros estudios o imprimirlo, si así lo desea</br>\n",
    "Además, muestra un gráfico en el cual se ven relacionados los atributos usados, indicando la correlación existente entre ellos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def graficoDispersion(variable):\n",
    "    '''\n",
    "    Función que recibe una columna del DataFrame y dibuja un gráfico de dispersión con la columna indicada. También almacena el gráfico como imagen en memoria\n",
    "\n",
    "    Parámetros:\n",
    "    ----------    \n",
    "        variable : Series\n",
    "            Serie de Pandas que contiene los datos que han de ser representados en el gráfico.\n",
    "\n",
    "    '''\n",
    "    sns.set(color_codes=True)\n",
    "\n",
    "    #Definimos el tamaño de la gráfica\n",
    "    plt.figure(figsize=(15,5))\n",
    "\n",
    "    #Rellenamos la gráfica con los valores deseados\n",
    "    sns.histplot(df[variable], color=\"blue\")\n",
    "\n",
    "    #Añadimos otros datos al gráfico y lo mostramos\n",
    "    plt.title(f\"Distribución de {variable}\", loc = \"center\", fontdict = {'fontsize':14, 'fontweight':'bold', 'color':'tab:blue'})\n",
    "    plt.ylabel(\"Densidad\", fontdict = {'fontsize':14, 'fontweight':'bold', 'color':'tab:green'})\n",
    "    plt.xlabel(variable, fontdict = {'fontsize':14, 'fontweight':'bold', 'color':'tab:green'})\n",
    "\n",
    "    #Guardamos el gráfico en memoria, por si fuera necesario emplear el análisis estadístico de estos datos por parte de los médicos\n",
    "    plt.savefig(f\"Distribución del {variable}.jpg\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseNumero(valor):\n",
    "    '''\n",
    "    Función que convierte la entrada de teclado a número\n",
    "\n",
    "    Parámetros\n",
    "    ---------\n",
    "    valor: string\n",
    "        Número con formato de String que deseamos convertir a int\n",
    "\n",
    "    Return\n",
    "    ---------\n",
    "    Devuelve el número con formato numérico para poder obtener la columna del array de columnas de acuerdo a su posición\n",
    "    '''\n",
    "    try:\n",
    "        numero = int(valor)  # Intenta convertir a entero\n",
    "        print(\"El número ingresado es:\", numero)\n",
    "    except ValueError:\n",
    "        try:\n",
    "            numero = float(valor)  # Intenta convertir a float\n",
    "            print(\"El número ingresado es:\", numero)\n",
    "        except ValueError:\n",
    "            print(\"El valor ingresado no es un número válido.\")\n",
    "    return(numero)\n",
    "\n",
    "print(\"Hola, a continuación le mostramos un listado de todas las variables que hay. Escriba el número que aparece a la izquierda de la columna para obtener el gráfico de distribución de dicha variable\")\n",
    "dfColumnas = pd.Series(df.columns.values)\n",
    "\n",
    "for i in dfColumnas.index:\n",
    "    print(i,dfColumnas[i])\n",
    "\n",
    "entrada=input()\n",
    "columnaG = parseNumero(entrada)\n",
    "\n",
    "while columnaG <0 or columnaG >=len(df.columns.values):\n",
    "    print(f\"Por favor, introduzca un número entre 0 y {len(df.columns.values)-1}\")\n",
    "    entrada=input()\n",
    "    columnaG = parseNumero(entrada)\n",
    "\n",
    "#Dibuja el gráfico de la variable indicada\n",
    "graficoDispersion(dfColumnas[columnaG])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graficoCorrelacion(df):\n",
    "    '''\n",
    "    Función que recibe el DataFrame y dibuja un gráfico de correlación de todos los atributos. También almacena el gráfico como imagen en memoria\n",
    "\n",
    "    Parámetros:\n",
    "    ----------    \n",
    "        df : DataFrame\n",
    "            DataFrame con todos los atributos.\n",
    "\n",
    "    '''\n",
    "    #Definimos el tamaño de la gráfica\n",
    "    plt.figure(figsize=(10,8))\n",
    "\n",
    "    #Rellenamos la gráfica con los valores deseados\n",
    "    correlacion = df.corr()\n",
    "    sns.heatmap(correlacion, annot=False, square=True, cmap='Blues')\n",
    "    \n",
    "    #Guardamos el gráfico en memoria, por si fuera necesario emplear el análisis estadístico de estos datos por parte de los médicos\n",
    "    plt.savefig(\"Correlación de los atributos.jpg\", bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "graficoCorrelacion(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Almacenamiento de los resultados\n",
    "Hemos decidido almacenar los resultados del uso de diferentes clasificadores en un diccionario, por si se perdiera la información en mitad de la ejecución, evitar que sea necesario volver a empezar desde el principio con el tratamiento de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "\n",
    "def reset_dict(results_path,new_dict):\n",
    "    \"\"\"\n",
    "    Resetea el fichero que tengamos en el disco duro con el diccionario de resultados que se indique.\n",
    "    \n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    results_path : string\n",
    "        string que contiene la ruta donde se almacenará el diccionario\n",
    "    \n",
    "    new_dict: dict\n",
    "        diccionario que será guardado sobreescribiendo el que ya existiese\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \n",
    "    \"\"\"\n",
    "    with open(results_path, 'wb') as handle:\n",
    "        pickle.dump(new_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "\n",
    "def load_results(results_path):\n",
    "    \"\"\"\n",
    "    Recupera el diccionario a partir del fichero en el disco duro\n",
    "    Si no existiese el fichero devuelve un diccionario de resultados vacio\n",
    "    \n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    results_path : string\n",
    "        string que contiene la ruta donde se almacenará el diccionario\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Un diccionario con el contenido del fichero o un diccionario vacio si el fichero no existe\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    results_dict = None\n",
    "    if os.path.isfile(results_path):\n",
    "        with open(results_path, 'rb') as handle:\n",
    "            results_dict = pickle.load(handle)\n",
    "            return results_dict\n",
    "    else:\n",
    "        return dict()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de diferentes experimentos\n",
    "Hemos decidido emplear diferentes clasificadores, por lo que hemos creado un diccionario con el nombre de los clasificadores como clave, y el método como valor, para poder emplearlos de manera conjunta en posteriores ejecuciones. Hemos creado dos funciones. La primera que se emplea es `get_sklenarn_data`, que divide los datos en $X$, que es el conjunto de atributos, y en  $y$, que es el conjunto de valores de la clase. Posteriormente se emplea la función `perform_exp`, que realiza particiones aleatorias en función del número de folds que se le indique y entrena el modelo. Si el modelo ya existe en el diccionario, lo recupera, de manera que no se repiten los experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def perform_exp(X,y,model,model_id,n_folds,results_path):\n",
    "    \"\"\"\n",
    "    La función recupera el diccionario a partir de la ruta proporcionada en results_path\n",
    "    Creamos un objeto StratifiedKFold hará tantas particiones como diga n_folds\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : numpy array\n",
    "        El conjunto de datos completo (atributos).\n",
    "    y : numpy array\n",
    "        El conjunto de datos completo (clases).   \n",
    "    model : \n",
    "        Un clasificador\n",
    "    model_id : \n",
    "        El identificador de ese clasificador que se almacenará en el diccionario de resultados\n",
    "    n_folds : \n",
    "        Número de folds de cada validación cruzada\n",
    "    results_path : string\n",
    "        Ruta donde se encuentra el diccionario serializado en el disco duro\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Un diccionario con el contenido del fichero o un diccionario vacio si el fichero no existe\n",
    "    \n",
    "    Raises\n",
    "    ------\n",
    "    FileNotFoundError\n",
    "        Aparece cuando se solicita un archivo o directorio que no existe\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        #Abro el archivo en modo lectura binaria\n",
    "        with open(results_path, \"rb\") as file:\n",
    "        # Cargar el diccionario desde el archivo utilizando pickle.load\n",
    "            dic = pickle.load(file)\n",
    "    except FileNotFoundError:\n",
    "        dic = {}\n",
    "        \n",
    "    #Crea el objeto StratifiedKFold\n",
    "    skf = StratifiedKFold(n_splits=n_folds, random_state = 0, shuffle =True)\n",
    "    #print(model.type())\n",
    "\n",
    "    #Divide X e y en las particiones en X_train, X_test, y_train, y_test\n",
    "    for fold, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "        key = (model_id, fold)\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        print(f\"Recuperando datos del modelo {model_id} para el fold Run F{fold}\")\n",
    "        if key in dic:\n",
    "            print(f\"Los datos para el modelo {model_id} y el fold {fold} ya están en el diccionario. Se recuperan del archivo\")\n",
    "           \n",
    "        else:\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            dic[key] = (y_test, y_pred)\n",
    "            with open(results_path, 'wb') as handle:\n",
    "                pickle.dump(dic, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recuperando datos del modelo Extra Trees para el fold Run F1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "def get_sklenarn_data(df,class_name):\n",
    "    '''\n",
    "    Saca X e y del dataFrame recibido:\n",
    "    Con df.drop eliminas columnas no desaeadas (class_name) para X y luego lo pasaré a array de numpy, y será esa columna en concreto.\n",
    "    \n",
    "    Parámetros\n",
    "    ----------\n",
    "    df : dataFrame\n",
    "        class_name: titulo de la coluna del dataframe anterior\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        arrays NumPy\n",
    "        X: array NumPy se representa como una matriz de dos dimensiones donde cada fila representa unos datos asociados a una y\n",
    "        y: array NumPy de una dimensión que será el dato de la variable objetivo correspondientes a cada instancia de entrenamiento en X\n",
    "    '''\n",
    "    # Extraer las características independientes y la clase\n",
    "    X = df.drop(class_name, axis=1).to_numpy()     \n",
    "    y = df[class_name].to_numpy() #me quedo tan solo con un array de de la variable indicada, en este caso el que queremos predecir\n",
    "    \n",
    "    #convierto un Dataframe o una Serie en un array NumPy\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "X,y = get_sklenarn_data(df,\"Cardio\") \n",
    "\n",
    "results_file_path = \"result.dict\"\n",
    "folds = 2\n",
    "\n",
    "\n",
    "# Borramos el diccionario para no tener resultados anteriores\n",
    "reset_dict(results_file_path,dict())\n",
    "# Como no existe nada, devuelve un diccionario vacio en el que no haya ninguna ejecución\n",
    "res_dict = load_results(results_file_path)\n",
    "\n",
    "#Creamos un listado con todos los clasificadores que se emplean, incluyendo su nombre y su método, que lo pasaremos a la función perform_exp\n",
    "clasificadores = {'Árbol de decisión': DecisionTreeClassifier(random_state=0), 'Random Forest': RandomForestClassifier(random_state=0), 'KNN': KNeighborsClassifier(), 'Regresión Logística': LogisticRegression(max_iter = 1000), 'XGBoost': XGBClassifier(), 'MLP': MLPClassifier(), 'Extra Trees': ExtraTreesClassifier()}#, 'SVC': SVC()}\n",
    "\n",
    "print(\"Lanzo experimentos por primera vez\")\n",
    "for i, j in zip(clasificadores.keys(), clasificadores.values()):\n",
    "    perform_exp(X,y,j,i,folds,results_file_path)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación de los modelos\n",
    "Una vez realizados todos los folds de los modelos, hemos creado la función `get_accuracy`, que obtiene las clases reales y predichas para cada fold, evaluándolo de manera individual. Por último calcula la media de la precisión de cada fold </br>\n",
    "Una vez obtenida esta función, hemos evaluado todos los modelos que hemos usado anteriormente, para determinar cual es el modelo que mejor predice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "\n",
    "def get_accuracy(dict_results, model_id, n_folds):\n",
    "    \"\"\"\n",
    "    Calcula la media de las accuracy para un clasificador en un número de folds determinado.\n",
    "\n",
    "    Parámetros\n",
    "    ----------\n",
    "        dict_results : dict\n",
    "            Diccionario que contiene los resultados de la ejecución de distintos clasificadores en diferentes folds.\n",
    "        model_id : str\n",
    "            Identificador del clasificador del que se desea obtener la accuracy.\n",
    "        n_folds : int\n",
    "            Número total de folds.\n",
    "\n",
    "    Return\n",
    "    ----------\n",
    "        float : Media de las accuracy para el clasificador en los diferentes folds.\n",
    "    \"\"\"\n",
    "    \n",
    "    accs = []\n",
    "    for i in range(n_folds):\n",
    "        y_true, y_pred = dict_results[(model_id, i)]\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        accs.append(acc)\n",
    "    return np.mean(accs)\n",
    "\n",
    "def get_acc_table(results_file_path, clasificadores, folds):\n",
    "    \"\"\"\n",
    "    Calcula la media de las accuracy para un clasificador en un número de folds determinado.\n",
    "\n",
    "    Parámetros\n",
    "    ----------\n",
    "        results_file_path : url\n",
    "            Drección url local que indica donde se encuentra almacenado el fichero con los datos. Posteriormente lo importará y creará un diccionario a partir de ese fichero.\n",
    "        clasificadores : list\n",
    "            Listado de clasificadores que han sido empleados y de los cuales se desea obtener sus medias.\n",
    "        n_folds : int\n",
    "            Número total de folds.\n",
    "\n",
    "    Return\n",
    "    ----------\n",
    "        DataFrame : DataFrame que almacena las medias de todos los clasificadores empleados.\n",
    "    \"\"\"\n",
    "    medias = {}\n",
    "    dict = load_results(results_path=results_file_path)\n",
    "    for i in clasificadores:\n",
    "        medias[i] = get_accuracy(dict, i, folds)\n",
    "    return pd.DataFrame(medias.items(), columns=['Cls', 'Acc'])\n",
    "\n",
    "get_acc_table(results_file_path,clasificadores.keys(),folds)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de confusión\n",
    "Al realizar el experimento hemos obtenido que el método que mejor clasifica los ejemplos es Regresión Logística, pero esto es cuando se realizan diferentes folds. A continuación, vamos a realizar una partición a los datos, entrenar la misma partición con todos los modelos y obtener la matriz de confusión. Para realizar la matriz de confusión hemos creado la función `representarMatriz`, que muestra la matriz de confusión y nuevamente la almacena en el ordenador, para que pueda ser visualizada y añadirla en algún informe, en caso de ser necesario\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def representarMatriz(modelo, matriz, clases, normalize=False):\n",
    "    \"\"\"\n",
    "    Realiza la matriz de confusión de los datos proporcionados.\n",
    "\n",
    "    Args:\n",
    "        modelo: string\n",
    "            Nombre del modelo para mostrarlo en el título del gráfico y guardar la imagen.\n",
    "        matriz : ndarray of shape (n_classes, n_classes)\n",
    "            Matriz de confusión obtenida mediante el método confusion_matrix\n",
    "        clases : int\n",
    "            Número de clases posibles\n",
    "    \"\"\"\n",
    "    \n",
    "    titulo = \"Matriz de confusión con \" + modelo\n",
    "\n",
    "    #Configuración del aspecto de la matriz de confusión\n",
    "    plt.imshow(matriz, interpolation='nearest', cmap=\"Blues\")\n",
    "    plt.title(titulo)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(clases))\n",
    "    plt.xticks(tick_marks, clases, rotation=20)\n",
    "    plt.yticks(tick_marks, clases)\n",
    "\n",
    "    if normalize:\n",
    "        matriz = matriz.astype('float') / matriz.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = matriz.max() / 2.\n",
    "    for i, j in itertools.product(range(matriz.shape[0]), range(matriz.shape[1])):\n",
    "        plt.text(j, i, matriz[i, j], horizontalalignment=\"center\", color=\"white\" if matriz[i, j] > thresh else \"black\")\n",
    "\n",
    "    #Configuración de la \"leyenda\" de la matriz\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True')\n",
    "    plt.xlabel('Predicted')\n",
    "\n",
    "    #Visualización de la matriz, para evitar que se superpongan en caso de usar más de un modelo\n",
    "    plt.show()\n",
    "\n",
    "    #Guardamos la matriz de confusión en memoria, por si fuera necesario emplear el análisis estadístico de estos datos por parte de los médicos\n",
    "    plt.savefig(f\"{titulo}.jpg\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, train_size=0.7) # 0.7, el 70% de los datos para entrenamiento\n",
    "tiempos = []\n",
    "\n",
    "for i, j in zip(clasificadores.keys(), clasificadores.values()):\n",
    "    #Creo el nuevo clasificador con Regresión Logistica y calculo su precisión\n",
    "    model = j\n",
    "    # Entrena el modelo con el 70% de los datos\n",
    "    tiempoInicio = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    tiempoTotal = time.time() - tiempoInicio\n",
    "\n",
    "    tiempos.append(tiempoTotal)\n",
    "\n",
    "    # Evalua el modelo con el 30% restante\n",
    "    y_predict = model.predict(X_test)\n",
    "    accuracy_score(y_test, y_predict)\n",
    "\n",
    "    matriz = confusion_matrix(y_test, y_predict) \n",
    "    representarMatriz(i, matriz, clases = range(2))\n",
    "\n",
    "#display(tiempos)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluar los diferentes métodos\n",
    "Vamos a evaluar la precisión de los diferentes modelos para conocer la tasa de acierto. Hemos decidido que, al tratarse de una enfermedad cardíaca donde el riesgo de un error es elevado, vamos a evaluar los errores con una función propia en la cual, clasificar a una persona como NO patológica (0), cuando sí que lo es, tiene una tasa de error de 1, mientras que clasificar como patológica (1) a una persona que no lo es, tiene una tasa de error de 0,5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "\n",
    "def accuracy_conservadora(y_real,y_pred):\n",
    "    \"\"\"\n",
    "    En esta función se obtiene una tasa de acierto conservadora, de manera que cuando se sobreestima el riesgo, el fallo vale la mitad (0,5).\\n\n",
    "    En caso de que el riesgo se infraestime, el fallo cuenta como 1.\n",
    "\n",
    "    Parámetros:\n",
    "    ----------\n",
    "        y_real : NDArray\n",
    "            Modelo proporcionado empleando un KNeighborsClassifier. No tiene ningún valor por defecto\n",
    "\n",
    "        y_pred : NDArray\n",
    "            Conjunto de datos de test para el modelo. No tiene ningún valor por defecto\n",
    "\n",
    "    Return:\n",
    "    ----------    \n",
    "        y_pred: array con un conjunto de predicciones del clasificador indicado\n",
    "\n",
    "    \"\"\"\n",
    "    errores_sobreestimacion = sum([1 for y_real, y_pred in zip(y_real, y_pred) if y_real < y_pred]) # Cuenta las predicciones que sobreestimaron\n",
    "    errores_infraestimacion = sum([1 for y_real, y_pred in zip(y_real, y_pred) if y_real > y_pred]) # Cuenta las predicciones que infraestimaron\n",
    "    accuracyCalculada = errores_infraestimacion + 0.5*errores_sobreestimacion\n",
    "    return 1-(accuracyCalculada/len(y_real))\n",
    "\n",
    "\n",
    "def evalua(X,y,clasificador,folds):\n",
    "    \"\"\"\n",
    "    Evalua el clasificador indicado, usando el número de folds indicado, los atributos X y la clase y. Devuelve accuracy_score y accuracy_conservadora\n",
    "    \n",
    "    En esta función se obtiene una tasa de acierto conservadora, de manera que cuando se sobreestima el riesgo, el fallo vale la mitad (0,5).\\n\n",
    "    En caso de que el riesgo se infraestime, el fallo cuenta como 1.\n",
    "\n",
    "    Parámetros:\n",
    "    ----------\n",
    "        X : DataFrame\n",
    "            Atributos independientes. Son los datos que se van a entrenar.\n",
    "\n",
    "        y : Series\n",
    "            Conjunto de resultados que se intentarán predecir.\n",
    "        \n",
    "        clasificador : Objeto `estimator` que implemente los métodos 'fit' y 'predict'\n",
    "            Objeto usado para entrenar los datos.\n",
    "\n",
    "        folds : int\n",
    "            Determina el número de divisiones de la validación cruzada.\n",
    "\n",
    "    Return:\n",
    "    ----------    \n",
    "        precision: int\n",
    "            Precisión de acierto en escala de 0 a 1, siendo 0 el valor más bajo y 1 el valor más alto. Todos los errores valen lo mismo\n",
    "        \n",
    "        precision_conservadora: int\n",
    "            Precisión de acierto en escala de 0 a 1, siendo 0 el valor más bajo y 1 el valor más alto. Cuando se sobreestima el riesgo, el fallo vale la mitad (0,5).\n",
    "\n",
    "    \"\"\"\n",
    "    prediccion = cross_val_predict(clasificador, X, y, cv=folds)\n",
    "    precision = accuracy_score(y, prediccion)\n",
    "    precision_conservadora = accuracy_conservadora(y, prediccion)\n",
    "    return precision, precision_conservadora\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "\n",
    "def evaluar_clasificadores(X, y, folds):\n",
    "    \"\"\"\n",
    "    Evalua todos los clasificadores, usando el número de folds indicado, los atributos X y la clase y. Devuelve accuracy_score y accuracy_conservadora\n",
    "    \n",
    "    En esta función se obtiene una tasa de acierto conservadora, de manera que cuando se sobreestima el riesgo, el fallo vale la mitad (0,5).\\n\n",
    "    En caso de que el riesgo se infraestime, el fallo cuenta como 1.\n",
    "\n",
    "    Parámetros:\n",
    "    ----------\n",
    "        X : DataFrame\n",
    "            Atributos independientes. Son los datos que se van a entrenar.\n",
    "\n",
    "        y : Series\n",
    "            Conjunto de resultados que se intentarán predecir.\n",
    "        \n",
    "        folds : int\n",
    "            Determina el número de divisiones de la validación cruzada.\n",
    "\n",
    "    Return:\n",
    "    ----------    \n",
    "        Resultados : dict\n",
    "            Conjunto de resultados de todos los clasificadores.\n",
    "\n",
    "    \"\"\"\n",
    "    resultados = {}\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    for i, j in zip(clasificadores.keys(), clasificadores.values()):\n",
    "        resultados[i]= evalua(X, y, j, folds)\n",
    "        \n",
    "    return resultados\n",
    "\n",
    "resultados = pd.DataFrame(evaluar_clasificadores(X, y, 5))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostramos la tabla con las precisiones y el tiempo de ejecución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabla = resultados.transpose()\n",
    "tabla.columns = ['Puntuación', 'Puntuación conservadora']\n",
    "tabla['Tiempo'] = tiempos\n",
    "display(tabla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRAFICA DE BARRAS\n",
    "# valores de las barras\n",
    "\n",
    "resultados2 = tabla.transpose()\n",
    "\n",
    "resultadosAcc = [r[1][0].round(2) for r in resultados2.items()]\n",
    "resultadosAcc_c = [r[1][1].round(2) for r in resultados2.items()]\n",
    "tiempos = [r[1][2].round(2)/10 for r in resultados2.items()]\n",
    "\n",
    "# configuración del gráfico\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "#Eje X\n",
    "barra = 0.25\n",
    "abscisas = resultados2.keys()\n",
    "x = np.arange(len(abscisas))\n",
    "\n",
    "#Genero las barras para cada conjunto de datos\n",
    "recta1 = ax.bar(x-2*barra/3, resultadosAcc, color = 'blue', width=barra, label='Accuracy')\n",
    "recta2 = ax.bar(x+barra/3, resultadosAcc_c, color = 'tab:blue', width=barra, label='AccuracyConservadora')\n",
    "recta3 = ax.bar(x+4*barra/3, tiempos, color = 'tab:orange', width=barra, label='Tiempo (segundos obtenidos dividido entre 10)')\n",
    "\n",
    "\n",
    "# agregar etiquetas de texto y título\n",
    "ax.set_xlabel('Clasificadores')\n",
    "ax.set_ylabel('Resultados')\n",
    "ax.set_title(f'Resultados de los {len(clasificadores)} clasificadores')\n",
    "ax.set_xticks(np.arange(len(clasificadores)) + barra / 3)\n",
    "ax.set_xticklabels(clasificadores)\n",
    "ax.legend()\n",
    "\n",
    "# agregar valores de las barras\n",
    "def autolabel(rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{:.2f}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "autolabel(recta1)\n",
    "autolabel(recta2)\n",
    "autolabel(recta3)\n",
    "\n",
    "\n",
    "# ajustar la figura\n",
    "plt.tight_layout()\n",
    "\n",
    "# mostrar gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
